{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f862a77-1f99-4372-853a-f3abc17ea4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4064c5da-f89b-468a-bff2-453710cfe68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43676f6-bc76-488f-b8d3-429f9ad58770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df7b52f-b44d-4276-bc79-1ce0b6a0a2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06d5f49-01c4-4e1f-98e5-5fb5266705ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = r\"C:\\Users\\venug\\Downloads\\55\\data\"\n",
    "outputmodel = r\"C:\\Users\\venug\\Downloads\\55\\vc\\VideoClassificationModel\"\n",
    "outputlabelbinarizer = r\"C:\\Users\\venug\\Downloads\\55\\vc\\videoclassificationbinarizer\"\n",
    "epoch=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e60f8a4c-070b-470b-8b18-c79ca2acdfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image being loaded\n"
     ]
    }
   ],
   "source": [
    "Sports_Labels= set(['badminton','chess','football'])\n",
    "print(\"image being loaded\")\n",
    "pathToImages = list(paths.list_images(datapath))\n",
    "data=[]\n",
    "labels=[]\n",
    "for images in pathToImages:\n",
    "    label = images.split(os.path.sep)[-2]\n",
    "    if label not in Sports_Labels:\n",
    "        continue\n",
    "    image = cv2.imread(images)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image,(224,224))\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374c07df-0407-4de3-b0fd-5f5e5a25252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4794de4b-b0ee-4b73-a81c-da84fffc51a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, Y_train, Y_test) = train_test_split(data, labels, test_size=0.25, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88805034-cc86-4915-9557-6996c4521055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "traininAugmentation = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,  # Corrected typo: Changed 'O' to '0'\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'  # Corrected typo: Replaced '-' with '='\n",
    ")\n",
    "validationAugmentation = ImageDataGenerator()\n",
    "\n",
    "mean = np.array([123.68, 116.779, 103.939],dtype=\"float32\") # Corrected syntax: Square brackets for array elements\n",
    "traininAugmentation.mean = mean\n",
    "validationAugmentation.mean = mean  # Corrected typo: Replaced 'traininAugmentation' with 'trainingAugmentation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7ca6051-4fb2-4b4d-9701-e3b2e8acdf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08a200f2-b6d0-4d33-a4ce-ec30cd30e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "epoch = 25\n",
    "learning_rate = 0.0001\n",
    "momentum = 0.9\n",
    "\n",
    "# Define the learning rate schedule\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate=learning_rate,\n",
    "    decay_steps=10000, # This should be adjusted based on your training data size\n",
    "    decay_rate=0.9 # Adjust the decay rate as needed\n",
    ")\n",
    "\n",
    "# Create the optimizer with the learning rate schedule\n",
    "opt = SGD(learning_rate=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b89e2-289c-4a1b-899d-4b7156cc41c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a443f4a2-86cc-407b-a098-2ec0b706b594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2188 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venug\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 4s/step - accuracy: 0.5849 - loss: 1.5960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x236cbd65f10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import Dense, Dropout, AveragePooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define your data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input, # Use preprocess_input for ResNet50\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input # Use preprocess_input for ResNet50\n",
    ")\n",
    "\n",
    "# Use the datapath variable for flow_from_directory\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    datapath,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Load the ResNet50 model with pre-trained weights\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = AveragePooling2D(pool_size=(7, 7))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(24, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 25\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ea15f3e-9116-4c6b-a97d-94dcf7cd123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1:(checked)\n",
    "import pickle\n",
    "model.save('VideoClassificationModel.keras')\n",
    "\n",
    "# Assuming 'lb' is your label binarizer\n",
    "# Save the label binarizer\n",
    "lbinarizer = open(r\"C:\\Users\\venug\\Downloads\\55\\vc\\videoclassificationbinarizer.pickle\", \"wb\")\n",
    "lbinarizer.write(pickle.dumps(lb))\n",
    "lbinarizer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc8267-b5d9-4db9-a3ca-4e67feda1393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
